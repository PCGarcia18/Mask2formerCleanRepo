{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random, struct, signal, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import preprocessing\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn.utils.class_weight as class_weight\n",
    "import torch.nn.functional as F\n",
    "from einops import repeat,rearrange\n",
    "from torch import nn, einsum\n",
    "import timm\n",
    "import logging\n",
    "\n",
    "\n",
    "class CyclicShift(nn.Module):\n",
    "    def __init__(self, displacement):\n",
    "        super().__init__()\n",
    "        self.displacement = displacement\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.roll(x, shifts=(self.displacement, self.displacement), dims=(1, 2))\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def create_mask(window_size, displacement, upper_lower, left_right):\n",
    "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
    "\n",
    "    if upper_lower:\n",
    "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
    "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
    "\n",
    "    if left_right:\n",
    "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
    "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
    "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
    "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_relative_distances(window_size):\n",
    "    indices = torch.tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n",
    "    distances = indices[None, :, :] - indices[:, None, :]\n",
    "    return distances\n",
    "\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        inner_dim = head_dim * heads\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.window_size = window_size\n",
    "        self.relative_pos_embedding = relative_pos_embedding\n",
    "        self.shifted = shifted\n",
    "\n",
    "        if self.shifted:\n",
    "            displacement = window_size // 2\n",
    "            self.cyclic_shift = CyclicShift(-displacement)\n",
    "            self.cyclic_back_shift = CyclicShift(displacement)\n",
    "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
    "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
    "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
    "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        if self.relative_pos_embedding:\n",
    "            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
    "            self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
    "        else:\n",
    "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
    "\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.shifted:\n",
    "            x = self.cyclic_shift(x)\n",
    "\n",
    "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        nw_h = n_h // self.window_size\n",
    "        nw_w = n_w // self.window_size\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
    "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
    "\n",
    "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
    "\n",
    "        if self.relative_pos_embedding:\n",
    "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
    "        else:\n",
    "            dots += self.pos_embedding\n",
    "\n",
    "        if self.shifted:\n",
    "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
    "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
    "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
    "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
    "        out = self.to_out(out)\n",
    "\n",
    "        if self.shifted:\n",
    "            out = self.cyclic_back_shift(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SwinBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
    "                                                                     heads=heads,\n",
    "                                                                     head_dim=head_dim,\n",
    "                                                                     shifted=shifted,\n",
    "                                                                     window_size=window_size,\n",
    "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
    "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim, hidden_dim=mlp_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention_block(x)\n",
    "        x = self.mlp_block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
    "        super().__init__()\n",
    "        self.downscaling_factor = downscaling_factor\n",
    "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
    "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
    "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class StageModule(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, layers, downscaling_factor, num_heads, head_dim, window_size,\n",
    "                 relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        assert layers % 2 == 0, 'Stage layers need to be divisible by 2 for regular and shifted block.'\n",
    "\n",
    "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
    "                                            downscaling_factor=downscaling_factor)\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(layers // 2):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
    "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
    "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
    "                          shifted=True, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_partition(x)\n",
    "        for regular_block, shifted_block in self.layers:\n",
    "            x = regular_block(x)\n",
    "            x = shifted_block(x)\n",
    "        return x.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "\n",
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self, *, hidden_dim, layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
    "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, layers=layers[0],\n",
    "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, layers=layers[1],\n",
    "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, layers=layers[2],\n",
    "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, layers=layers[3],\n",
    "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim * 8, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.stage1(img)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = x.mean(dim=[2, 3])\n",
    "        return self.mlp_head(x)\n",
    "\n",
    "def swin_t(hidden_dim=96, layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
    "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)\n",
    "\n",
    "def swin_s(hidden_dim=96, layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
    "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)\n",
    "\n",
    "def swin_b(hidden_dim=128, layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
    "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)\n",
    "\n",
    "def swin_l(hidden_dim=192, layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
    "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=4\n",
    "nclases=24\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model= SwinTransformer(channels=B,num_classes=nclases,head_dim=32,\n",
    "    hidden_dim=96,layers=(2, 2, 6, 2),heads=(3, 6, 12, 24), # esto es un swin_t\n",
    "    # OJO, debe ser window_size<=sizex/downscaling_factors, en este caso 32/(4*2*2*2)\n",
    "    window_size=7,downscaling_factors=(2, 2, 2, 2),relative_pos_embedding=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights converted and saved to: /home/pablo.canosa/wip/python_notebooks/Francisco Net Adaptations/SWIN_v3_Multi_True.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/pablo.canosa/wip/python_notebooks/Francisco Net Adaptations/SWIN_v3_Multi_True.pkl'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "def convert_pt_to_pkl(pt_path, pkl_path=None):\n",
    "    \"\"\"\n",
    "    Convert a PyTorch .pt weights file to a .pkl file\n",
    "    \n",
    "    :param pt_path: Path to the input .pt file\n",
    "    :param pkl_path: Optional path for the output .pkl file. \n",
    "                     If not provided, will use the same path with .pkl extension\n",
    "    :return: Path to the saved .pkl file\n",
    "    \"\"\"\n",
    "    # Load the PyTorch weights\n",
    "    weights = torch.load(pt_path, map_location='cpu')\n",
    "    \n",
    "    # If no pkl path is provided, generate one\n",
    "    if pkl_path is None:\n",
    "        pkl_path = pt_path.replace('.pt', '.pkl')\n",
    "    \n",
    "    # Ensure the file ends with .pkl\n",
    "    if not pkl_path.endswith('.pkl'):\n",
    "        pkl_path += '.pkl'\n",
    "    \n",
    "    # Convert tensor to numpy if needed\n",
    "    def convert_tensors_to_numpy(obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            return obj.numpy()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_tensors_to_numpy(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [convert_tensors_to_numpy(v) for v in obj]\n",
    "        return obj\n",
    "    \n",
    "    # Convert weights\n",
    "    converted_weights = convert_tensors_to_numpy(weights)\n",
    "    \n",
    "    # Save to pkl\n",
    "    with open(pkl_path, 'wb') as f:\n",
    "        pickle.dump(converted_weights, f)\n",
    "    \n",
    "    print(f\"Weights converted and saved to: {pkl_path}\")\n",
    "    return pkl_path\n",
    "\n",
    "# Example usage\n",
    "input_path = \"/home/pablo.canosa/wip/python_notebooks/Francisco Net Adaptations/SWIN_v3_Multi_True.pt\"\n",
    "output_path = \"/home/pablo.canosa/wip/python_notebooks/Francisco Net Adaptations/SWIN_v3_Multi_True.pkl\"\n",
    "\n",
    "convert_pt_to_pkl(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights in the .pkl file:\n",
      "<class '__main__.SwinTransformer'>\n"
     ]
    }
   ],
   "source": [
    "pkl_path = \"/home/pablo.canosa/wip/python_notebooks/Francisco Net Adaptations/SWIN_v3_Multi_True.pkl\"\n",
    "\n",
    "# Read and print the name of each weight in the .pkl file with its shape\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "    print(\"Weights in the .pkl file:\")\n",
    "    print(type(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 16])\n",
      "tensor([[-0.1139,  0.1084, -0.1421,  ..., -0.0234,  0.1215, -0.0913],\n",
      "        [-0.1081,  0.1847, -0.1854,  ..., -0.1557, -0.2156,  0.0497],\n",
      "        [-0.1334, -0.1602,  0.0853,  ...,  0.2444, -0.0774,  0.0720],\n",
      "        ...,\n",
      "        [-0.2083,  0.2058,  0.1933,  ..., -0.0186, -0.1812, -0.2471],\n",
      "        [ 0.2478,  0.0812, -0.1902,  ...,  0.0447, -0.0468,  0.0804],\n",
      "        [-0.0717, -0.0075,  0.0836,  ...,  0.0836,  0.1509, -0.0478]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class '__main__.SwinTransformer'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mstate_dict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage1.patch_partition.linear.weight\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the weights from the .pt file to the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swin_francisco/lib/python3.8/site-packages/torch/nn/modules/module.py:2104\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \n\u001b[1;32m   2071\u001b[0m \u001b[38;5;124;03mIf :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2106\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2107\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class '__main__.SwinTransformer'>."
     ]
    }
   ],
   "source": [
    "print(model.state_dict()[\"stage1.patch_partition.linear.weight\"].shape)\n",
    "print(model.state_dict()[\"stage1.patch_partition.linear.weight\"])\n",
    "\n",
    "# Load the weights from the .pt file to the model\n",
    "model.load_state_dict(weights, strict=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin_francisco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
